<!DOCTYPE html>
<html lang="pt-br">
    <head>
        <meta charset="UTF-8"/>
        <link rel="icon" href="imagens/favicon.ico"/>
        <title>Aprenda Python Pentest</title>
        <link rel="stylesheet" href="css/estilo.css"/>
    </head>
    <body>
        <div>
            <header>
                <h1>Aprenda Python Pentest</h1>
                <menu>
                    <li><a href="index.html">Página Inicial</a></li>
                    <li><a href="contato.html">Contato!</a></li>
                    <li><a href="tudo-sobre-python-pentest-1.html">Tudo sobre Python Pentest Parte 1!</a></li>
                    <li><a href="tudo-sobre-python-pentest-2.html">Tudo sobre Python Pentest Parte 2!</a></li>
                    <li><a href="tudo-sobre-python-pentest-3.html">Tudo sobre Python Pentest Parte 3!</a></li>
                    <li><a href="tudo-sobre-python-pentest-4.html">Tudo sobre Python Pentest Parte 4!</a></li>
                    <li><a href="tudo-sobre-python-pentest-5.html">Tudo sobre Python Pentest Parte 5!</a></li>
                    <li><a href="tudo-sobre-python-pentest-6.html" onclick="alert('Você já Está na Matéria desse Link!'); return false">Tudo sobre Python Pentest Parte 6!</a></li>
                    <li><a href="tudo-sobre-python-pentest-7.html">Tudo sobre Python Pentest Parte 7!</a></li>
                    <li><a href="tudo-sobre-python-pentest-8.html">Tudo sobre Python Pentest Parte 8!</a></li>
                    <li><a href="tudo-sobre-python-pentest-9.html">Tudo sobre Python Pentest Parte 9!</a></li>
                    <li><a href="tudo-sobre-python-pentest-10.html">Tudo sobre Python Pentest Parte 10!</a></li>
                </menu>
            </header>
           
<h2>Tudo sobre Python Pentest Parte 6</h2>

<h3>Identificando Index Of</h3>

<p>Agora nós vamos fazer o nosso script identificar pastas com Index Of, que tem listagem de arquivos e diretórios. Isso economiza tempo de execução, já que, com o Index Of, podemos identificar os arquivos sem fazer bruteforce.</p>

<p>No caso, nós filtraremos vendo o que tem na tag <q>title</q> do HTML.</p>

<p>Altere o if url da função check assim:</p>

<pre>
<code>
if url + "/" == local:
    print(f"Pasta: {url}/ - CODE: {code}")
    re = requests.get(url + "/")

    if re.status_code == 200:
        html = re.text

        if "&lt;title&gt;Index of" in html:
            print("\u2514 -&gt; Index of")
    else:
        pastas.append(url)
</code>
</pre>

<p>Daí, pra pegar os arquivos dentro da pasta de Index of, podemos verificar os arquivos baseados na tag <q>a</q> do HTML. Deixe o if de url assim:</p>

<pre>
<code>
if url + "/" == local:
    print(f"Pasta: {url}/ - CODE: {code}")
    re = requests.get(url + "/")

    if re.status_code == 200:
        html = re.text

        if "&lt;title&gt;Index of" in html:
            try:
                for h in html.split("Parent Directory")[1].split("&lt;a href=\""):
                    arq = h.split("&lt;/a&gt;")[0].split("\"")[0]

                    if len(arq) &gt; 2:
                        print(f"{'\u2514'} {arq}")
            except:
                pass
        else:
            pastas.append(url)
    else:
        pastas.append(url)
</code>
</pre>

<h3>Implementando Threads</h3>

<p>Como explicado anteriormente, um thread permite que duas ou mais funções sejam executadas praticamente ao mesmo tempo.</p>

<p>Para implementarmos um thread no nosso Dirb, podemos fazer a importação com <code>import threading</code> e do time acima do nosso código. E na função looping, faça assim:</p>

<pre>
<code>
def looping(wordl, dom):
    for w in wordl:
        item = w.replace("\n", "")
        url = f"{dom}{item}"
        th = threading.Thread(target = check, args = (url,))
        th.start()
</code>
</pre>

<p>O problema é que uma wordlist com 11 linhas, gerará 11 threads, mas pode dar problemas com wordlists maiores (como uma com 4000 linhas, tipo a do verdadeiro Dirb localizada em <q>/usr/share/dirb/wordlists/common.txt</q>).</p>

<p>Diferente de um script de scan de portas, o HTTP trabalha em uma camada mais alta em redes, e isso acaba fazendo que tanto o servidor quanto o cliente tenha maior processamento para tratar as requisições. Então, criar muitas threads pode causar sobrecarga em ambos, fazendo que o teste fique mais lento do que com as funções normais.</p>

<p>Para limtar as Threads, podemos usar um semáforo, assim, colocando na função looping:</p>

<pre>
<code>
def looping(wordl, dom):
    global semaforo
    semaforo = threading.Semaphore(3)  # Definindo o semáforo

    for w in wordl:
        item = w.replace("\n", "")
        url = f"{dom}{item}"
        th = threading.Thread(target = check, args = (url,))
        th.start()
</code>
</pre>

<p>E na função check, apenas temos que identar tudo dentro no with com o semáforo, veja como fica no início da função:</p>

<pre>
<code>
def check(url):
    with semaforo:
        re = requests.head(url, allow_redirects = False)
        code = re.status_code
</code>
</pre>

<p>Mas ele dará alguns bugs, então altere a função check assim, dentro do if url:</p>

<pre>
<code>
if url + "/" == local:
    dirP = f"Pasta: {url}/ - CODE: {code}"
    re = requests.get(url + "/")

    if re.status_code == 200:
        html = re.text

        if "&lt;title&gt;Index of" in html:
            print(f"{dirP}\n{'\u2514'} -> Index of")
        else:
            print(dirP)
            pastas.append(url)
    else:
        print(dirP)
        pastas.append(url)
</code>
</pre>

<p>Ele mostrará três condições, mas imprimirá apenas uma por execução da função (do thread, no caso).</p>

<p>Só que o código ainda dará um erro que não exibirá os arquivos das pastas. Para isso, corrigiremos a função looping, que adicionará os threads numa lista e fará outra repetição:</p>

<pre>
<code>
def looping(wordl, dom):
    global semaforo
    semaforo = threading.Semaphore(3)  # Definindo o semáforo

    thrd = list()
    for w in wordl:
        item = w.replace("\n", "")
        url = f"{dom}{item}"
        th = threading.Thread(target = check, args = (url,))
        thrd.append(th)
        th.start()
        
    for t in thrd:
        t.join()
</code>
</pre>

<p>PS: Pra melhorar a exibição, podemos fazer assim, na função check, dentro do with semaforo:</p>

<pre>
<code>
with semaforo:
    msg = f"Testando {url}"
    print(f"{msg}", end = "")
    print(" " * 100, end = "\r") # O \r sobreescreve a mensagem anterior
    re = requests.head(url, allow_redirects = False)
    code = re.status_code
</code>
</pre>

<h3>Criando um Spider</h3>

<p>Um spider é uma ferramenta que tem várias utilidades, mas a utilidade mais básica dele é acessar um site pra buscar links relacionados a ele, é uma forma de mapear o ambiente de uma forma interna. Uma outra função importante que ele tem é de mapear informações importantes, como endereços de e-mail e telefone. Ele pode procurar informações sobre algo dentro de uma página. No caso, nós procuraremos links internos dentro de um site, não links externos (como o do Facebook, por exemplo).</p>

<p>Para criarmos nosso spider, precisaremos instalar a biblioteca <code>beautifulsoup4</code>. Pra começar, faça esse código:</p>

<pre>
<code>
import requests

url = str(input("Insira o domínio: "))

re = requests.get(url)
html = re.text

print(html)
</code>
</pre>

<p>Vendo isso aí, poderíamos verificar os links olhando as tags <q>a</q>. Nos exemplos anteriores usamos o split, mas ele pode dar alguns bugs, por isso usaremos o BeautifulSoup, que permite tratar linguagens de marcação como o HTML e o XML. Veja um exemplo básico:</p>

<pre>
<code>
import requests
from bs4 import BeautifulSoup

url = str(input("Insira o domínio: "))

re = requests.get(url)
html = re.text
soup = BeautifulSoup(html, "html.parser")

print(soup)    
</code>
</pre>

<p>Claro que o código acima faz praticamente o mesmo do anterior, mas podemos filtrar o que queremos, dessa forma:</p>

<pre>
<code>
print(soup.find_all("a")) # Filtra apenas as tags "a" e salva numa lista
</code>
</pre>

<p>E no lugar do print acima, faça esse for:</p>

<pre>
<code>
for a in soup.find_all("a"):
    print(a)
</code>
</pre>

<p>E pra pegar só o link dos atributos href:</p>

<pre>
<code>
for a in soup.find_all("a"):
    print(a["href"])
</code>
</pre>

<p>Os links externos já costumam estar completos (como o redirecionando pra algo no Facebook ou no Youtube), o que nós queremos é os links internos, que tem os caminhos absolutos (como <q>/admin/login.php</q>), nesse caso teremos que montar o link pra podermos acessar o mesmo. Pra isso, faça assim:</p>

<pre>
<code>
for a in soup.find_all("a"):
    link = a["href"]
    
    if "://" in link:
        print(link)
</code>
</pre>

<p>E pra extrair o domínio:</p>

<pre>
<code>
if "://" in link:
    print(link.split("://")[1].split("/")[0])
</code>
</pre>
    
<p>Só que dessa forma, pode dar alguns problemas e retornar coisas como <q>facebook.com?callback=https://outrosite.com/</q>, e a função pode não conseguir pegar o link que queremos, então alteraremos o código assim:</p>

<pre>
<code>
import requests
from bs4 import BeautifulSoup

url = str(input("Insira o domínio: "))
dominio = url.split("://")[1].split("/")[0]

re = requests.get(url)
html = re.text
soup = BeautifulSoup(html, "html.parser")

for a in soup.find_all("a"):
    link = a["href"]

    if "://" in link:
        domLink = link.split("://")[1].split("/")[0]

        if dominio == domLink:
            print(link)
</code>
</pre>

<p>Pra ele pegar caminhos absolutos do site, coloque esse elif dentro do for, abaixo do primeiro if:</p>

<pre>
<code>
if "://" in link:
    domLink = link.split("://")[1].split("/")[0]

    if dominio == domLink:
        pass
elif link[0] == "/":
    print(link)
</code>
</pre>

<p>Para pegar o protocolo, vá no início do script e faça isso:</p>

<pre>
<code>
url = str(input("Insira o domínio: "))
protocolo = url.split("://")[0]
dominio = url.split("://")[1].split("/")[0]

print(protocolo) 
exit()
</code>
</pre>

<p>E depois assim:</p>

<pre>
<code>
url = str(input("Insira o domínio: "))
protocolo = url.split("://")[0]
dominio = url.split("://")[1].split("/")[0]
semiurl = f"{protocolo}://{dominio}"

print(semiurl)
exit()
</code>
</pre>

<p>Daí, retire o print ali e o exit. É importante a semiurl não ter a barra no final, pra não causar conflitos com o caminho absoluto.</p>

<p>E daí, no elif, basta colocar assim:</p>

<pre>
<code>
elif link[0] == "/":
    link = f"{semiurl}{link}"
    print(link)
</code>
</pre>

<p>Daí, só falta fazer o caminho relativo, basta colocar o link no else, assim:</p>

<pre>
<code>
if "://" in link:
    domLink = link.split("://")[1].split("/")[0]

    if dominio == domLink:
        pass
elif link[0] == "/":
    link = f"{semiurl}{link}"
else:
    link = f"{url}{link}"
    print(link)
</code>
</pre>

<p>PS: Isso dará um bug na exibição dos links relativos, que corrigiremos ainda nessa aula.</p>

<p>Daí no caso, colocaremos tudo isso acima numa função, dessa forma:</p>

<pre>
<code>
def checkLink(link):
    if "://" in link:
        domLink = link.split("://")[1].split("/")[0]

        if dominio == domLink: # Coloque domínio como global
            print(link)
    elif link[0] == "/":
        link = f"{semiurl}{link}"
        print(link)
    else:
        link = f"{url}{link}"
        print(link)
</code>
</pre>

<p>E no for apenas deixe isso:</p>

<pre>
<code>
for a in soup.find_all("a"):
    link = a["href"]
    checkLink(link)
</code>
</pre>

<p>Mas ele não pegará subdominíos, nesse caso podemos alterar a função assim, no if mais interno:</p>

<pre>
<code>
if dominio in domLink:
    print(link)
</code>
</pre>

<p>Podemos verificar outras tags, como a form, por exemplo, fazendo outro for abaixo do primeiro (que pode ser comentado por enquanto):</p>

<pre>
<code>
for f in soup.find_all("form"):
    link = f["action"]
    print(link)
</code>
</pre>

<p>Só que no caso, caso não encontre o atributo action na tag form, pode dar erro, nesse caso, podemos fazer um filtro assim nos dois fors:</p>

<pre>
<code>
""" Comentado por enquanto:
for a in soup.find_all("a"):
    try:
        link = a["href"]
        checkLink(link)
    except KeyError:
        pass
"""

for f in soup.find_all("form"):
    try:
        link = f["action"]
        print(link)
    except KeyError:
        pass
</code>
</pre>

<p>Depois, tire o print e coloque o a chamada da função, assim:</p>

<pre>
<code>
for f in soup.find_all("form"):
    try:
        link = f["action"]
        checkLink(link)
    except KeyError:
        pass
</code>
</pre>

<p>Comente o for acima também e coloque abaixo dele este, que segue o mesmo raciocínio pra pegar o iframe:</p>

<pre>
<code>
for i in soup.find_all("iframe"):
    try:
        link = i["src"]
        checkLink(link)
    except KeyError:
        pass
</code>
</pre>

<p>Agora descomente tudo e rode.</p>

<p>Daí, coloque todos os fors numa função:</p>

<pre>
<code>
def findLinks(soup):
    for a in soup.find_all("a"):
        try:
            link = a["href"]
            checkLink(link)
        except KeyError:
            pass

    for f in soup.find_all("form"):
        try:
            link = f["action"]
            checkLink(link)
        except KeyError:
            pass

    for i in soup.find_all("iframe"):
        try:
            link = i["src"]
            checkLink(link)
        except KeyError:
            pass
</code>
</pre>

<p>E no final do código, basta invocar ela:</p>

<pre>
<code>
soup = BeautifulSoup(html, "html.parser")

findLinks(soup)
</code>
</pre>

<p>Pra salvar tudo numa lista, faça assim:</p>

<pre>
<code>
soup = BeautifulSoup(html, "html.parser")

global linksF
linksF = list()

findLinks(soup)
</code>
</pre>

<p>E altere a função checkLink assim:</p>

<pre>
<code>
def checkLink(link):
    try:
        if "://" in link:
            domLink = link.split("://")[1].split("/")[0]

            if dominio in domLink:
                if link not in linksF:
                    linksF.append(link)
                    print(link)
        elif link[0] == "/":
            link = f"{semiurl}{link}"

            if link not in linksF:
                linksF.append(link)
                print(link)
        else:
            link = f"{url}{link}"

            if link not in linksF:
                linksF.append(link)
                print(link)
    except IndexError:
        pass
</code>
</pre>

<p>E no final do código, faça assim:</p>

<pre>
<code>
findLinks(soup)

print(linksF)
</code>
</pre>

<p>Daí, apenas substitua o último print por isso:</p>

<pre>
<code>
if len(linksF) >= 1:
    for l in linksF:
        protocolo = l.split("://")[0]
        dominio = l.split("://")[1].split("/")[0]
        semiurl = f"{protocolo}://{dominio}"

        re = requests.get(l)
        html = re.text
        soup = BeautifulSoup(html, "html.parser")

        findLinks(soup)
</code>
</pre>

<p>O problema é que ele ainda dá uns bugs com alguns arquivos encontrados, para isso, vamos garantir que tenha uma barra no final, fazendo apenas isso:</p>

<pre>
<code>
url = str(input("Insira o domínio: "))

if url[:-1] != "/":
    url += "/"
</code>
</pre>

<ul>
    <li><a href="tudo-sobre-python-pentest-5.html">Parte Anterior da Matéria!</a></li>
    <li><a href="tudo-sobre-python-pentest-7.html">Continuação da Matéria!</a></li>
</ul>

        </div>
    </body>
</html>